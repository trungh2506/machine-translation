
from random import randint
from pydantic import BaseModel
import torch
import re,string
from model.transformer import Seq2SeqTransformer
from utils.utils import Translation
from langdetect import detect
from langdetect import detect_langs
import streamlit as st
from streamlit_option_menu import option_menu
from nltk.translate.bleu_score import sentence_bleu
import pandas as pd

en_sents = open('data/en_sents', "r", encoding='utf-8').read().splitlines()
vi_sents = open('data/vi_sents', "r", encoding='utf-8').read().splitlines()

def preprocessing(data):
    # Lo·∫°i b·ªè d·∫•u c√¢u v√† k√Ω t·ª± ƒë·∫∑c bi·ªát
    data = [line.translate(str.maketrans('', '', string.punctuation)) for line in data]
    # Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh ch·ªØ th∆∞·ªùng
    data = [line.lower() for line in data]
    # Lo·∫°i b·ªè c√°c kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi c√¢u
    data = [line.strip() for line in data]
    # Thay th·∫ø c√°c kho·∫£ng tr·∫Øng k√©p b·∫±ng m·ªôt kho·∫£ng tr·∫Øng ƒë∆°n
    data = [re.sub("\s+", " ", line) for line in data]
    return data

en_sents = preprocessing(en_sents)
vi_sents = preprocessing(vi_sents)

DEVICE = torch.device('cuda')
TRANSFORMER_EN2VI_WEIGHTS = 'weights/en2vi.pth'
TRANSFORMER_VI2EN_WEIGHTS = 'weights/vi2en.pth'
vocab_src_en = 'weights/src_vocab_1.pkl'
vocab_tgt_vi = 'weights/tgt_vocab_1.pkl'
vocab_src_vi = 'weights/src_vocab_2.pkl'
vocab_tgt_en = 'weights/tgt_vocab_2.pkl'


EMB_SIZE = 512
NHEAD = 8 # embed_dim must be divisible by num_heads
FFN_HID_DIM = 512
BATCH_SIZE = 64
NUM_ENCODER_LAYERS = 4
NUM_DECODER_LAYERS = 4
DROP_OUT = 0.1

def load_en2vi_model():
    translation = Translation(vocab_src_en, vocab_tgt_vi, DEVICE)
    SRC_VOCAB_SIZE, TGT_VOCAB_SIZE = translation.len_vocab()

    # Load transformer model
    transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,
                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM,DROP_OUT)

    transformer.load_state_dict(torch.load(TRANSFORMER_EN2VI_WEIGHTS))
    transformer.eval()
    transformer = transformer.to(DEVICE)

    return transformer, translation  

def load_vi2en_model():
    translation = Translation(vocab_src_vi, vocab_tgt_en, DEVICE)
    SRC_VOCAB_SIZE, TGT_VOCAB_SIZE = translation.len_vocab()

    # Load transformer model
    transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,
                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM,DROP_OUT)

    transformer.load_state_dict(torch.load(TRANSFORMER_VI2EN_WEIGHTS))
    transformer.eval()
    transformer = transformer.to(DEVICE)

    return transformer, translation 

def preprocess_input(text):
    text = (lambda ele: ele.translate(str.maketrans('', '', string.punctuation)))
    text = (lambda ele: ele.lower())
    text = (lambda ele: ele.strip())
    text = (lambda ele: re.sub("\s+", " ", ele))
    return text


def get_bleu_score():
    rand = [randint(170000, 200000) for i in range(10)]
    test_set = [
        [en_sents[i] for i in rand],
        [vi_sents[i] for i in rand]
    ]
    results = []
    for i in range(len(test_set[0])):
        transformer, translation = load_en2vi_model()
        source = test_set[0][i]
        actual = test_set[1][i]
        predict = translation.translate(transformer, source)
        bleu = bleu_score(actual, predict)
        results.append((source, actual, predict, bleu))
    return results

def get_bleu_score_vi2en():
    rand = [randint(170000, 200000) for i in range(10)]
    test_set = [
        [vi_sents[i] for i in rand],
        [en_sents[i] for i in rand]
    ]
    results = []
    for i in range(len(test_set[0])):
        transformer, translation = load_vi2en_model()
        source = test_set[0][i]
        actual = test_set[1][i]
        predict = translation.translate(transformer, source)
        bleu = bleu_score(actual, predict)
        results.append((source, actual, predict, bleu))
    return results

def bleu_score(reference, candidate):
    reference = [reference.split()]
    candidate = candidate.split()  
    return sentence_bleu(reference, candidate)


st.set_page_config(page_title='BLEU Score', page_icon="üí©")
st.page_link("pages/2_ü§ñ_Translation.py", label="Translation Page", icon="1Ô∏è‚É£")
st.title('ƒê·ªô ƒëo BLEU')

st.write('BLEU l√† vi·∫øt t·∫Øt c·ªßa Bilingual Evaluation Understudy, l√† ph∆∞∆°ng ph√°p ƒë√°nh gi√° m·ªôt b·∫£n d·ªãch d·ª±a tr√™n c√°c b·∫£n d·ªãch tham kh·∫£o, ƒë∆∞·ª£c gi·ªõi thi·ªáu trong paper BLEU: a Method for Automatic Evaluation of Machine Translation). BLEU ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ s·ª≠ d·ª•ng trong d·ªãch m√°y (Machine Translation), nh∆∞ng th·ª±c t·∫ø, ph√©p ƒëo n√†y c≈©ng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c nhi·ªám v·ª• nh∆∞ t√≥m t·∫Øt vƒÉn b·∫£n, nh·∫≠n d·∫°ng gi·ªçng n√≥i, sinh nh√£n ·∫£nh v..v.. B√™n c·∫°nh ƒë√≥ ph√©p ƒëo n√†y ho√†n to√†n c√≥ th·ªÉ s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng b·∫£n d·ªãch c·ªßa nh√¢n vi√™n.')

st.subheader('BLEU cho m√¥ h√¨nh English to Vietnamese')
results = get_bleu_score()
df = pd.DataFrame(results, columns=['Source', 'Actual', 'Predicted', 'BLEU Score'])
st.dataframe(df)

st.subheader('BLEU cho m√¥ h√¨nh Vietnamese to English')
results = get_bleu_score_vi2en()
df2 = pd.DataFrame(results, columns=['Source', 'Actual', 'Predicted', 'BLEU Score'])
st.dataframe(df2)